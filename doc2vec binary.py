"""
Yatian Li
30 May 2023
"""
import csv
import chardet
import gensim
from gensim.models.doc2vec import TaggedDocument
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import precision_score, f1_score
import nltk
nltk.download('stopwords')
from nltk.corpus import stopwords

# define a function to preprocess the data for Doc2Vec
def preprocess_data(data):
    stop_words = set(stopwords.words('english'))
    docs = []
    for i, row in enumerate(data):
        words = [word for word in row['message'].split() if word not in stop_words]
        docs.append(TaggedDocument(words=words, tags=[i]))
    return docs

# open the first CSV file and read its contents
# Detect the encoding of the file
with open('negative_commits.csv', 'rb') as f:
    result = chardet.detect(f.read())
    
# Read the file using the detected encoding
with open('negative_commits.csv', newline='', encoding=result['encoding']) as f:
    reader = csv.DictReader(f)
    data1 = [row for row in reader]

# add an extra column to the first data
for row in data1:
    row['category'] = 0

# open the second CSV file and read its contents
with open('security_patches.csv', newline='', encoding= 'utf-8') as f:
    reader = csv.DictReader(f)
    data2 = [row for row in reader]

# add an extra column to the second data
for row in data2:
    row['category'] = 1

# combine the two datasets for columns with same header name
combined_data = data1 + data2

# preprocess the data for Doc2Vec
docs = preprocess_data(combined_data)

# train a Doc2Vec model
"""
vector_size: the dimentionality of the feature vectors generated by the model
window: the maximum distance between the current and predicted word within a sentence
min_count: the minimum frequency of words that must occur in the corpus to be included in the model's vocabulary
workers: number of worker threads will be used to train the model in parallel
epochs: number of iteration over the corpus during training.
"""
model = gensim.models.Doc2Vec(docs, vector_size=100, window=5, min_count=50, workers=5, epochs=20)

# get the vectors for the documents
vectors = [model.infer_vector(row['message'].split()) for row in combined_data]
labels = [1 if row['category'] == 1 else 0 for row in combined_data]
negative_count = 0
positive_count = 0
for label in labels:
    if label == 0:
        negative_count += 1
    else:
        positive_count += 1
print("positive labels: ",positive_count, "negative labels: ",negative_count)

# split the data into training and testing sets
train_vectors, test_vectors, train_labels, test_labels = train_test_split(vectors, labels, test_size=0.2, train_size=0.8, stratify=labels)
negative_count = 0
positive_count = 0
for label in train_labels:
    if label == 0:
        negative_count += 1
    else:
        positive_count += 1
print("train positive labels: ",positive_count, "train negative labels: ",negative_count) 


"""
SVM classifier
"""
# Train an SVM classifier
classifier = SVC(kernel='linear', random_state=42)
classifier.fit(train_vectors, train_labels)

# Predict the labels for the test vectors
predicted_labels = classifier.predict(test_vectors)

# Calculate precision and F1 score
precision = precision_score(test_labels, predicted_labels)
f1 = f1_score(test_labels, predicted_labels)
SVM_accuracy = classifier.score(test_vectors, test_labels)

print("SVM accuracy: ", SVM_accuracy)

"""
logistic regression classifier
"""
# Support Vector Machines; Nearest Neighbor; Decision Trees 
clf = LogisticRegression()
clf.fit(train_vectors, train_labels)

# Predict labels for the test data using the trained classifier
predicted_labels = clf.predict(test_vectors)

# get the vocabulary of the Doc2Vec model
vocab = model.wv.key_to_index
# print the size of the vocabulary
print('Vocabulary size:', len(vocab))

# Calculate precision, F1 score, accuracy of the classifier on the testing data
precision = precision_score(test_labels, predicted_labels)
f1 = f1_score(test_labels, predicted_labels)
accuracy = clf.score(test_vectors, test_labels)
print("logistic regression Precision: ", precision, "F1 Score: ", f1, "Accuracy: ", accuracy)
